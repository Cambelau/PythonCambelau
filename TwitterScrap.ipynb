{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "consumer_key = \"MDmShnm2IlhUYdOshDwQqWMM0\" #Your API/Consumer key \n",
    "consumer_secret = \"6YGgrCcJGGEb0ngdElSZnPs5WMXUKa9D1ivNog9UifRrsY5mOp\" #Your API/Consumer Secret Key\n",
    "access_token = \"3242472841-cSvAIMDHtnenaCjFNh5esjX8nQ3DSgY19Ltp4ot\"    #Your Access token key\n",
    "access_token_secret = \"hvGZHV6TU0rtCOWDymXqtuFRwLQIFpXYc4JlbGPJIarSE\" #Your Access token Secret key\n",
    "# bearer_token = \"AAAAAAAAAAAAAAAAAAAAADbXfAEAAAAACq%2BktorLfXw4RSWR5%2Fsej3Hu%2F1M%3D6vvbQCzNvkCYtaX9u5xuX42dI2wp2ZBdnpbxVuVCpoOMPnpeCq\"  # BEARER_TOKEN\n",
    "\n",
    "#Pass in our twitter API authentication key\n",
    "auth = tweepy.OAuth1UserHandler(\n",
    "    consumer_key, consumer_secret,\n",
    "    access_token, access_token_secret\n",
    ")\n",
    "\n",
    "proxy= {\n",
    "    'http': \"http://u251579:Melfos1012!@10.38.253.17:8080/\" ,\n",
    "    'https': \"https://u251579:Melfos1012!@10.38.253.17:8080/\",\n",
    "    }\n",
    "#Instantiate the tweepy API\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True,proxy=\"http://u251579:Melfos1012!@10.38.253.17:8080\")\n",
    "\n",
    "search_query = \"hello\"\n",
    "no_of_tweets =150\n",
    "\n",
    "userList=[[\"@afpfr\",\"REAL\"],[\"@bfm_tg\",\"FAKE\"],[\"@lemondefr\",\"REAL\"],[\"@lemondefr\",\"REAL\"],[\"@bfmtv\",\"REAL\"],[\"@L_ThinkTank\",\"REAL\"],[\"@Mediavenir\",\"FAKE\"]]\n",
    "\n",
    "try:\n",
    "    #The number of tweets we want to retrieved from the search\n",
    "    # tweets = api.search_tweets(q=search_query, count=no_of_tweets)\n",
    "    # tweets = api.user_timeline(screen_name=userAfp,count=500)\n",
    "    # #Pulling Some attributes from the tweet\n",
    "    # attributes_container = [[tweet.user.name,tweet.user.screen_name,tweet.created_at, tweet.favorite_count, tweet.source,  tweet.text,\"REAL\"] for tweet in tweets]\n",
    "    # tweets = api.user_timeline(screen_name=userFake,count=500)\n",
    "    # #Pulling Some attributes from the tweet\n",
    "    # attributes_container2 = [[tweet.user.name,tweet.user.screen_name,tweet.created_at, tweet.favorite_count, tweet.source,  tweet.text,\"FAKE\"] for tweet in tweets]\n",
    "\n",
    "    # #Creation of column list to rename the columns in the dataframe\n",
    "    attributes_container=[]\n",
    "\n",
    "    for username in userList:\n",
    "        tweets = api.user_timeline(screen_name=username[0],count=200)\n",
    "        attributes_container += ([[tweet.user.name,tweet.user.screen_name,tweet.created_at, tweet.favorite_count, tweet.source,  tweet.text,username[1]] for tweet in tweets])    \n",
    "\n",
    "    #Creation of Dataframe\n",
    "    columns = [\"User\", \"title\",\"Date Created\", \"Number of Likes\", \"Source of Tweet\", \"text\",\"label\"]\n",
    "    tweets_df = pd.DataFrame(attributes_container,columns=columns)\n",
    "except BaseException as e:\n",
    "    print('Status Failed On,',str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.81%\n",
      "True Positive [ 26 212]\n",
      "True Negative [161  21]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "#Read the data\n",
    "# df=pd.read_csv('D:\\\\DataFlair\\\\news.csv')\n",
    "df=tweets_df\n",
    "#Get shape and head\n",
    "df.shape\n",
    "df.head()\n",
    "#DataFlair - Get the labels\n",
    "labels=df.label\n",
    "labels.head()\n",
    "#DataFlair - Split the dataset\n",
    "x_train,x_test,y_train,y_test=train_test_split(df['text'], labels, test_size=0.3, random_state=7)\n",
    "#DataFlair - Initialize a TfidfVectorizer\n",
    "my_stop_word_list =  get_stop_words('french')\n",
    "tfidf_vectorizer=TfidfVectorizer(stop_words=my_stop_word_list, max_df=0.7)\n",
    "\n",
    "#DataFlair - Fit and transform train set, transform test set\n",
    "tfidf_train=tfidf_vectorizer.fit_transform(x_train) \n",
    "tfidf_test=tfidf_vectorizer.transform(x_test)\n",
    "#DataFlair - Initialize a PassiveAggressiveClassifier\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(tfidf_train,y_train)\n",
    "\n",
    "#DataFlair - Predict on the test set and calculate accuracy\n",
    "y_pred=pac.predict(tfidf_test)\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%')\n",
    "\n",
    "#DataFlair - Build confusion matrix\n",
    "confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8a350205ea34ba74239cd6929d3990b019e6b8d57840845f3f6e0fd91aa9f40"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
